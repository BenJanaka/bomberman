\begin{thebibliography}{1}

\bibitem{PommAnalysis}
Bin Chen, Jiarong Qiu, Sairam~Kamal Raj, Shuwei Shi, and Wei Cheng.
\newblock Pommermanfight: A detailed analysis of reinforcement algorithms.

\bibitem{AlanPresentation}
Frank de~Morrée, Ida Stoustrup, and Iestyn Watkin.
\newblock Outplaying humans in bomberman using deep q-learning, 2019.

\bibitem{GoulartBomberman}
\'{I}caro Goulart Faria Motta~França, Aline Paes, and Esteban Clua.
\newblock {\em Learning How to Play Bomberman with Deep Reinforcement and
  Imitation Learning}, pages 121--133.
\newblock 11 2019.

\bibitem{ExploreConnectionistQLearning}
Joseph Groot~Kormelink, Madalina Drugan, and Marco Wiering.
\newblock Exploration methods for connectionist q-learning in bomberman.
\newblock 01 2018.

\bibitem{Lecture}
Ullrich Köthe.
\newblock Fundamentals of machine learning, 2021.

\bibitem{BeatBomberman2018}
Juarez Monteiro, Roger Granada, Rodrigo Barros, and Rafael Pinto.
\newblock Beating bomberman with artificial intelligence.
\newblock 10 2018.

\bibitem{UBHD-68505368}
Sudharsan Ravichandiran.
\newblock {\em Hands-on reinforcement learning with Python}.
\newblock Packt Publishing, Birmingham, UK, 2018.
\newblock Includes bibliographical references. - Description based on online
  resource; title from title page (Safari, viewed August 2, 2018).

\bibitem{Pommerman}
Dhruv Shah, Nihal Singh, and Chinmay Talegaonkar.
\newblock Multi-agent strategies for pommerman, 2017.

\bibitem{DeepQNet}
Jordi Torres.
\newblock Deep q-network (dqn)-i, 2020.

\end{thebibliography}
